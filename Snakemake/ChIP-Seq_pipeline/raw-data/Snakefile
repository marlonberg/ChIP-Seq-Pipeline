READS=[]
CONTROLREADS=[]
READS2=[]
CONTROLREADS2=[]
genome="/media/ATLAS_Genomes_Annotations/human/GRCH38/primary_assembly/star_index"


#read filenames from targetfile and write them in lists
with open("targets.csv") as targets:
	lines=targets.readlines()
	lines[0]=re.split(',', lines[0])
	for i in range(1,len(lines)):
		lines[i]=re.split(',', lines[i])
		READS.append(lines[i][lines[0].index("fastqRead1")][:-6])
		CONTROLREADS.append(lines[i][lines[0].index("fastqControl1")][:-6])
		#second reads for paired-end
		if lines[i][lines[0].index("fastqRead2")]!="-":
			READS2.append(lines[i][lines[0].index("fastqRead2")][:-6])
		else:
			READS2.append(lines[i][lines[0].index("fastqRead2")])
		if lines[i][lines[0].index("fastqControl2")]!="-":
			CONTROLREADS2.append(lines[i][lines[0].index("fastqControl2")][:-6])
		else:
			CONTROLREADS2.append(lines[i][lines[0].index("fastqControl2")])


reads=READS+CONTROLREADS
reads2=[]
for i in READS2:
	if i != "-":
		reads2.append(i)
for i in CONTROLREADS2:
	if i != "-":
		reads2.append(i)
allReads=reads+reads2


#define targets
rule all:
	input: expand("nonEmpty/trimmed/star/tagDir/Peaks/{read}_Peaks.bed", read=READS)

#delete empty sequences
rule nonEmpty:
	input: expand("{reads}.fastq", reads=allReads)
	output: expand("nonEmpty/{reads}.nonEmpty.fastq", reads=allReads)
	run:
		for i in input:
			j= output[input.index(i)]	
			shell("""awk 'BEGIN {{RS = "@NS" ; FS = "\\n" ; ORS = ""}} {{if ($2) print "@NS"$0}}' """ + i + " > " + j)
		
#qualitycontrol with FastQC
rule fastqc:
	input: expand("nonEmpty/{reads}.nonEmpty.fastq", reads=allReads)
	output: expand("nonEmpty/FastQCfiles/{reads}.nonEmpty_fastqc/fastqc_data.txt", reads=allReads)
	shell: "fastqc -o nonEmpty/FastQCfiles {input} --extract"

#trim reads with homerTools if necessary, map with star
rule readMapping:
	input: readList=expand("nonEmpty/{reads}.nonEmpty.fastq", reads=reads),
		   fastqcData=expand("nonEmpty/FastQCfiles/{reads}.nonEmpty_fastqc/fastqc_data.txt",reads=reads),
		   genome=genome
	output: expand("nonEmpty/trimmed/star/{reads}/Aligned.out.sam", reads=reads)
	run:
		for i in input.fastqcData:
			#open fastqc data
			with open(i) as filetoread:
				lines=filetoread.readlines()
				for j in range(len(lines)):
					if re.search('>>Sequence Length Distribution',lines[j]):
						splitLine=re.split('\s+', lines[j])
						currRead1=input.readList[input.fastqcData.index(i)]
						currRead2=(READS2+CONTROLREADS2)[input.fastqcData.index(i)]
						sliceStart=9
						sliceEnd=-15
						sl=slice(sliceStart,sliceEnd)
						#check if paired-end
						if currRead2!="-":
							#open fastqc data of second read
							with open("nonEmpty/FastQCfiles/"+currRead2+"_fastqc/fastqc_data.txt") as file2:
								lines2=file2.readlines()
								for k in range(len(lines2)):
									if re.search('>>Sequence Length Distribution',lines2[k]):
										splitLine2=re.split('\s+', lines2[k])
										#check if first read has to be trimmed
										if splitLine[3]=="fail":
											#trim first read and move files to subdirectory trimmed
											shell("homerTools trim " + currRead1)
											shell("mv " + currRead1 + ".trimmed trimmed")
											shell("mv " + currRead1 + ".lengths trimmed")
											currRead1="trimmed/" + currRead1 + ".trimmed"
											sliceStart=17
											sliceEnd=-23
										#check if second read has to be trimmed
										if splitLine2[3]=="fail":
											#trim second read and move files to subdirectory trimmed
											shell("homerTools trim " + currRead2)
											shell("mv " + currRead2 + ".trimmed trimmed")
											shell("mv " + currRead2 + ".lengths trimmed")
											currRead1="trimmed/" + currRead2 + ".trimmed"
										#map paired end reads
										shell("STAR --readFilesIn " + currRead1 + currRead2 +" --genomeDir {input.d} --outFileNamePrefix nonEmpty/trimmed/star/" + currRead1[sl] + "/")
						else:
							#check if read has to be trimmed
							if splitLine[3]=="fail":
								#trim read and move files to subdirectory trimmed
								shell("homerTools trim " + currRead1)
								shell("mv " + currRead1 + ".trimmed trimmed")
								shell("mv " + currRead1 + ".lengths trimmed")
								currRead1="trimmed/" + currRead1 + ".trimmed"
								sliceStart=17
								sliceEnd=-23
							#map read
							shell("STAR --readFilesIn " + currRead1 + " --genomeDir {input.genome} --outFileNamePrefix nonEmpty/trimmed/star/" + currRead1[sl] + "/")

#create Tag directories with Homer
rule makeTagDir:
	input: expand("nonEmpty/trimmed/star/{reads}/Aligned.out.sam", reads=reads)
	output: expand("nonEmpty/trimmed/star/tagDir/{reads}", reads=reads)
	run:
		for i in input:
			j= output[input.index(i)]
			shell("makeTagDirectory " + str(j) + " " + str(i))

#call Peaks with Homer
rule peakCalling:
	input: a=expand("nonEmpty/trimmed/star/tagDir/{read}", read=READS),b=expand("nonEmpty/trimmed/star/tagDir/{controlread}", controlread=CONTROLREADS)
	output: expand("nonEmpty/trimmed/star/tagDir/Peaks/{read}_Peaks.txt", read=READS)
	run:
		for i in input.a:
			j= output[input.a.index(i)]
			k=input.b[input.a.index(i)]
			shell("findPeaks " + i + " -style factor -o " + j +" -i " + k)


#convert peakfiles to BED format
rule convertToBed:
	input: expand("nonEmpty/trimmed/star/tagDir/Peaks/{read}_Peaks.txt", read=READS)
	output: expand("nonEmpty/trimmed/star/tagDir/Peaks/{read}_Peaks.bed", read=READS)
	run:
		for i in input:
			j= output[input.index(i)]
			shell("pos2bed.pl " +i+" > " +j)


