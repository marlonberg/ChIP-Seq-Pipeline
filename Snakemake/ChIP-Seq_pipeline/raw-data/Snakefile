import math

READS=[]
CONTROLREADS=[]
READS2=[]
CONTROLREADS2=[]
genome=config["genome"]
peakType=config["peakType"]


#read filenames from targetfile and write them in lists
with open("targets.csv") as targets:
	lines=targets.readlines()
	lines[0]=re.split(',', lines[0])
	for i in range(1,len(lines)):
		lines[i]=re.split(',', lines[i])
		READS.append(lines[i][lines[0].index("fastqRead1")][:-6])
		CONTROLREADS.append(lines[i][lines[0].index("fastqControl1")][:-6])
		#second reads for paired-end
		if lines[i][lines[0].index("fastqRead2")]!="-":
			READS2.append(lines[i][lines[0].index("fastqRead2")][:-6])
		else:
			READS2.append(lines[i][lines[0].index("fastqRead2")])
		if lines[i][lines[0].index("fastqControl2")]!="-":
			CONTROLREADS2.append(lines[i][lines[0].index("fastqControl2")][:-6])
		else:
			CONTROLREADS2.append(lines[i][lines[0].index("fastqControl2")]) #empty strings need to be added to avoid index errors afterwards


reads=READS+CONTROLREADS
reads2=[]
for i in READS2:
	if i != "-":
		reads2.append(i)
for i in CONTROLREADS2:
	if i != "-":
		reads2.append(i)
allReads=reads+reads2

#define targets
rule all:
	input: expand("nonEmpty/trimmed/star/tagDir/Peaks/{read}_Peaks.bed", read=READS)

#delete empty sequences
rule nonEmpty:
	input: expand("{reads}.fastq", reads=allReads)
	output: expand("nonEmpty/{reads}.nonEmpty.fastq", reads=allReads)
	run:
		for i in input:
			j= output[input.index(i)]	
			shell("""awk 'BEGIN {{RS = "@NS" ; FS = "\\n" ; ORS = ""}} {{if ($2) print "@NS"$0}}' """ + i + " > " + j)
		
#qualitycontrol with FastQC
rule fastqc:
	input: expand("nonEmpty/{reads}.nonEmpty.fastq", reads=allReads)
	output: expand("nonEmpty/FastQCfiles/{reads}.nonEmpty_fastqc/fastqc_data.txt", reads=allReads)
	log: "log/log.txt"
	shell: """echo "FastQC Analysis:\n" >> {log}
		fastqc -o nonEmpty/FastQCfiles {input} --extract 2>> {log}"""

#function for calculating standart deviation
def stdev(line):
	split = re.split('\s', line)
	values = [float(split[1]), float(split[2]), float(split[3]), float(split[4])]
	st = math.sqrt(sum((v - sum(values) / len(values)) ** 2 for v in values) / (len(values) - 1))
	return st

#trim with fastx_trimmer
#the trim condition is the standart deviation of the bases for every position
rule trim:
	input: reads=expand("nonEmpty/{reads}.nonEmpty.fastq", reads=allReads),
		   fastqcFile=expand("nonEmpty/FastQCfiles/{read}.nonEmpty_fastqc/fastqc_data.txt", read=reads[0]),
	output: expand("nonEmpty/trimmed/{reads}.nonEmpty.fastq.trimmed", reads=allReads)
	log: "log/log.txt"
	run: 	
		count=0
		file=open(str(input.fastqcFile))
		lines = file.readlines()
		for j in range(len(lines)):
			if re.search('>>Per sequence GC content', lines[j]):
				endOfRead=j-2
		for j in range(len(lines)):
			if re.search('>>Per base sequence content', lines[j]):
				for k in range(j + 2, endOfRead):
					count+=1
					if stdev(lines[k]) <= 10:
						start = count+1
						while stdev(lines[k]) <= 10:
							k += 1
							count+=1
						end = count-3
						break
				break
		shell("""echo "\n\ntrimming with fastx_trimmer:\n" >> {log}""")
		for i in input.reads:
			shell("fastx_trimmer -Q33 -f " + str(start) + " -l " + str(end) + " -i " + i + " -o " + output[input.reads.index(i)] + " -v >> {log}")


#map reads with STAR
rule readMapping:
	input: readsToMap=expand("nonEmpty/trimmed/{reads}.nonEmpty.fastq.trimmed", reads=reads)
	output: expand("nonEmpty/trimmed/star/{reads}/Aligned.sortedByCoord.out.bam", reads=reads)
	run:
		for read in input.readsToMap:
			read2=(READS2+CONTROLREADS2)[input.readsToMap.index(read)]
			#check if paired-end
			if read2 !="-":
				shell("STAR --readFilesIn " + read + " " + read2 + " --genomeDir {genome} --outFileNamePrefix nonEmpty/trimmed/star/" + reads[input.readsToMap.index(read)] +"/ --outSAMtype BAM SortedByCoordinate")
			else:
				shell("STAR --readFilesIn " + read + " --genomeDir {genome} --outFileNamePrefix nonEmpty/trimmed/star/" + reads[input.readsToMap.index(read)]+"/ --outSAMtype BAM SortedByCoordinate")




#create Tag directories with Homer
rule makeTagDir:
	input: expand("nonEmpty/trimmed/star/{reads}/Aligned.sortedByCoord.out.bam", reads=reads)
	output: expand("nonEmpty/trimmed/star/tagDir/{reads}", reads=reads)
	log: "log/log.txt"
	run:
		shell("""echo "\n\ncreate Tag directories with Homer:\n" >> {log}""")
		for i in input:
			j= output[input.index(i)]
			shell("makeTagDirectory " + j + " " + i + " 2>> {log}")

#call Peaks with Homer
rule peakCalling:
	input: a=expand("nonEmpty/trimmed/star/tagDir/{read}", read=READS),b=expand("nonEmpty/trimmed/star/tagDir/{controlread}", controlread=CONTROLREADS)
	output: expand("nonEmpty/trimmed/star/tagDir/Peaks/{read}_Peaks.txt", read=READS)
	log: "log/log.txt"
	run:
		shell("""echo "\n\ncall Peaks with Homer:\n" >> {log}""")
		for i in input.a:
			j= output[input.a.index(i)]
			k=input.b[input.a.index(i)]
			shell("findPeaks " + i + " -style " + peakType + " -o " + j +" -i " + k + " 2>> {log}")


#convert peakfiles to BED format
rule convertToBed:
	input: expand("nonEmpty/trimmed/star/tagDir/Peaks/{read}_Peaks.txt", read=READS)
	output: expand("nonEmpty/trimmed/star/tagDir/Peaks/{read}_Peaks.bed", read=READS)
	run:
		for i in input:
			j= output[input.index(i)]
			shell("pos2bed.pl " + i +" > " + j)


